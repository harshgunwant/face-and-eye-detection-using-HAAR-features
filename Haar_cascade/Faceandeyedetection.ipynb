{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faceandeyedetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDo_ctBig8Na"
      },
      "source": [
        "#face recognition\n",
        "\n",
        "#importing the libraries\n",
        "import cv2\n",
        "\n",
        "#detecting the features\n",
        "face_detector=cv2.CascadeClassifier(\"/content/drive/MyDrive/Haar_cascade/haarcascade_frontalface_default.xml\")\n",
        "eye_detector=cv2.CascadeClassifier(\"/content/drive/MyDrive/Haar_cascade/haarcascade_eye.xml\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85DzNar7qSuV"
      },
      "source": [
        "##defining a function that will detect\n",
        "def detection(gray, frame):     # function requires a gray scale image and a frame from the video.\n",
        "    faces=face_detector.detectMultiScale(gray, 1.3, 5)        #defining the rectangle\n",
        "    for (x,y,w,h) in faces:                       #faces will return us x,y,h and w of the frame.\n",
        "        cv2.rectangle(gray,(x,y),(x+w,y+h), (0,0,255),2)        #to have the rectangles on the faces\n",
        "        roi_gray=gray[y:y+h,x:x+w]      #for detecting eye in gray scale image in cascading.(eyes coordinates will be smaller )\n",
        "        roi_color=frame[y:y+h,x:x+w]    #for placing the rectangles on the original colored frame.\n",
        "        eyes=eye_detector.detectMultiScale(roi_gray, 1.1, 3)\n",
        "        for (ex,ey,ew,eh) in eyes:\n",
        "          cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),1.5)    ##roi_color is a sub-frame of frame.\n",
        "    return frame\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "ueeP-s1Th0tl",
        "outputId": "cebdcd97-4eba-4b7d-dcb1-00f36bf29eec"
      },
      "source": [
        "#detecting features from the webcam\n",
        "video_capture=cv2.VideoCapture(0)\n",
        "# 0 for default webcam.\n",
        "# 1 for any usb cam.\n",
        "\n",
        "#applying detect function to all the incoming images\n",
        "while True:        #not applying for loop as we want the loop to be infinite.\n",
        "    _,frame=video_capture.read()    #read returns 2 elements. ## to get the last frame.\n",
        "    gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #we need a grayscaleimage(source, conversion code)\n",
        "\n",
        "    #can now apply the detect function\n",
        "    canvas=detection(gray,frame)   ##canvas is output of the detection function.\n",
        "    cv2.imshow(\"Video\", canvas)    #display the processed images in an animated window.\n",
        "    #video is window_name i.e, just a string. canvas is the image to be displayed.\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):## will go on until enter or q key is pressed.\n",
        "        break\n",
        "\n",
        "##turning off the webcam\n",
        "video_capture.release()\n",
        "#destroying the window in which the images are displayed and stored\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a72c0ad7216f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m        \u001b[0;31m#not applying for loop as we want the loop to be infinite.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo_capture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#read returns 2 elements. ## to get the last frame.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#we need a grayscaleimage(source, conversion code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#can now apply the detect function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UrASA42BlMu"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}